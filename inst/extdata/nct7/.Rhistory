name <- gsub('.*\">', '', gsub("</a>.*", "", fni))
size <- gsub(".* ", "", fni)
fniv <- c(fniv, paste0("`", name, "`", " = ", size))
}
# check for h5se completeness
cond.assays <- length(fniv[grepl("assays", fniv)]) = 1
cond.se <- length(fniv[grepl("se", fniv)]) = 1
sv <- c(sv, paste(fniv, collapse = ";"))
if(!(cond.assays & cond.se)){fnexclude <- c(fnexclude, f)}
}
}
dm[grepl("h5se", dm[,1]), 4] <- sv
dm <- dm[!dm[,1] %in% fnexclude,] # filter incomplete h5se files
return(dm)
}
get_rmdl <- function(fn = NULL, show.files = FALSE,
which.class = c("rg", "gm", "gr", "test"),
which.type = c("h5se", "h5"),
url = "https://recount.bio/data/",
dfp = "downloads", download = TRUE,
verbose = TRUE, sslver = FALSE){
if(verbose){message("Retrieving data dirnames from server...")}
# set up rcurl call
ftpuseopt <- ifelse(show.files, FALSE, TRUE)
dirlistopt <- ifelse(show.files, FALSE, TRUE)
dn <- RCurl::getURL(url, ftp.use.epsv = ftpuseopt, dirlistonly = dirlistopt,
.opts = list(ssl.verifypeer = sslver))
if(verbose){message("Getting file data from server.")}
sm <- servermatrix(dn)
if(show.files & !download){
if(verbose){message("Showing server file data")}
prmatrix(sm)
}
if(is.null(fn)){
# clean query results
str1 <- ifelse(which.type == "h5", "\\.", ".*")
str2 <- ifelse(which.type == "h5", "$", ".*")
typestr <- paste0(str1, which.type, str2)
filt.type <- grepl(paste0(".*", which.type,".*"), sm[,1])
filt.all <- filt.type & grepl(paste0(".*", which.class,".*"), sm[,1])
dnc <- sm[filt.all, 1]
if(length(dnc) == 0){
stop("No files of class and type found.")
} else if(length(dnc) > 1){
tsv <- as.numeric(gsub(".*_", "", dnc)) # timestamps
tsf <- which(tsv == max(tsv))[1] # first instance
dnc <- dnc[tsf]
}
} else{
dnc <- fn
check.cond1 <- grepl("(\\.h5$|.*h5se.*)", dnc)
check.cond2 <- dnc %in% sm[,1]
condpass <- check.cond1 & check.cond2
if(!condpass){stop("Provided fn not found on server.")}
}
if(!download){
message("File confirmed on server. Returning.")
return(dnc)
}
# manage download loc
dct1 <- ifelse(!dir.exists(dfp) & !dfp == "", try(dir.create(dfp)), TRUE)
dfp.dn <- paste(c(dfp, dnc), collapse = "/")
if(which.type == "h5"){
dct2 <- try(file.create(dfp.dn))
} else{dct2 <- try(dir.create(dfp.dn))}
if(!(dct1 & dct2)){
stop("There was a problem with the download dest. Do you have write access?")
}
dn.url <- paste0(url, dnc)
if(which.type == "h5"){fl.clean <- ""} else{
fnv <- unlist(strsplit(as.character(sm[2,4]), ";"))
fl.clean <- gsub("( .*|`)", "", fnv)
}
if(verbose){message("Downloading file(s)...")}
dll <- list()
for(i in 1:length(fl.clean)){
fpath <- paste0(c(dn.url, fl.clean[i]), collapse = "")
cf = RCurl::CFILE(paste0(dfp.dn, fl.clean[i]), mode="wb")
dll[[i]] <- try(RCurl::curlPerform(url = fpath, writedata = cf@ref,
.opts = list(ssl.verifypeer = sslver)))
}
if(length(dll[dll==0]) == length(dll)){
if(verbose){message("Finished download, returning file path.")}
return(dfp.dn)
} else{
if(verbose){message("Download incomplete for file ", fl.clean[which(dll!=0)])}
return(NULL)
}
return(NULL)
}
get_rmdl(show.files = TRUE, download = FALSE)
get_rmdl <- function(fn = NULL, show.files = FALSE,
which.class = c("rg", "gm", "gr", "test"),
which.type = c("h5se", "h5"),
url = "https://recount.bio/data/",
dfp = "downloads", download = TRUE,
verbose = TRUE, sslver = FALSE){
if(verbose){message("Retrieving data dirnames from server...")}
# set up rcurl call
ftpuseopt <- ifelse(show.files, FALSE, TRUE)
dirlistopt <- ifelse(show.files, FALSE, TRUE)
dn <- RCurl::getURL(url, ftp.use.epsv = ftpuseopt, dirlistonly = dirlistopt,
.opts = list(ssl.verifypeer = sslver))
if(verbose){message("Getting file data from server.")}
sm <- servermatrix(dn)
if(show.files & !download){
if(verbose){message("Showing server file data")}
prmatrix(sm)
}
if(is.null(fn)){
# clean query results
str1 <- ifelse(which.type == "h5", "\\.", ".*")
str2 <- ifelse(which.type == "h5", "$", ".*")
typestr <- paste0(str1, which.type, str2)
filt.type <- grepl(paste0(".*", which.type,".*"), sm[,1])
filt.all <- filt.type & grepl(paste0(".*", which.class,".*"), sm[,1])
dnc <- sm[filt.all, 1]
if(length(dnc) == 0){
stop("No files of class and type found.")
} else if(length(dnc) > 1){
tsv <- as.numeric(gsub(".*_", "", dnc)) # timestamps
tsf <- which(tsv == max(tsv))[1] # first instance
dnc <- dnc[tsf]
}
} else{
dnc <- fn
check.cond1 <- grepl("(\\.h5$|.*h5se.*)", dnc)
check.cond2 <- dnc %in% sm[,1]
condpass <- check.cond1 & check.cond2
if(!condpass){stop("Provided fn not found on server.")}
}
if(!download){
message("File confirmed on server. Returning.")
return(dnc)
}
# manage download loc
dct1 <- ifelse(!dir.exists(dfp) & !dfp == "", try(dir.create(dfp)), TRUE)
dfp.dn <- paste(c(dfp, dnc), collapse = "/")
if(which.type == "h5"){
dct2 <- try(file.create(dfp.dn))
} else{dct2 <- try(dir.create(dfp.dn))}
if(!(dct1 & dct2)){
stop("There was a problem with the download dest. Do you have write access?")
}
dn.url <- paste0(url, dnc)
if(which.type == "h5"){fl.clean <- ""} else{
fnv <- unlist(strsplit(as.character(sm[2,4]), ";"))
fl.clean <- gsub("( .*|`)", "", fnv)
}
if(verbose){message("Downloading file(s)...")}
dll <- list()
for(i in 1:length(fl.clean)){
fpath <- paste0(c(dn.url, fl.clean[i]), collapse = "")
cf = RCurl::CFILE(paste0(dfp.dn, fl.clean[i]), mode="wb")
dll[[i]] <- try(RCurl::curlPerform(url = fpath, writedata = cf@ref,
.opts = list(ssl.verifypeer = sslver)))
}
if(length(dll[dll==0]) == length(dll)){
if(verbose){message("Finished download, returning file path.")}
return(dfp.dn)
} else{
if(verbose){message("Download incomplete for file ", fl.clean[which(dll!=0)])}
return(NULL)
}
return(NULL)
}
get_rmdl(show.files = TRUE, download = FALSE, sslver = FALSE)
servermatrix <- function(dn, url = "https://recount.bio/data/",
printmatrix = TRUE, verbose = FALSE, recursive = TRUE){
dt <- unlist(strsplit(dn, "\r\n"))
dt <- gsub('(.*\">|/</a>|</a>)', "", dt)
dt <- dt[grepl("remethdb", dt)]
drows <- lapply(as.list(dt), function(x){
return(unlist(strsplit(gsub("[ ]+", ";", x), ";")))
})
dm <- do.call(rbind, drows)
colnames(dm) <- c("filename", "date", "time", "size (bytes)")
if(recursive){
sv <- c() # file sizes vector
fnv <- dm[grepl("h5se", dm[,1]), 1]
fnexclude <- c()
for(f in fnv){
fv <- RCurl::getURL(paste0(url, f, "/"), dirlistonly = TRUE,
.opts = list(ssl.verifypeer = sslver))
fvv <- unlist(strsplit(fv, "\r\n"))
which.start <- which(grepl("Index", fvv))[2] + 1
which.end <- which(grepl("/pre", fvv)) - 1
fvf <- fvv[which.start:which.end]
fniv <- c()
for(fni in fvf){
name <- gsub('.*\">', '', gsub("</a>.*", "", fni))
size <- gsub(".* ", "", fni)
fniv <- c(fniv, paste0("`", name, "`", " = ", size))
}
# check for h5se completeness
cond.assays <- length(fniv[grepl("assays", fniv)]) = 1
cond.se <- length(fniv[grepl("se", fniv)]) = 1
sv <- c(sv, paste(fniv, collapse = ";"))
if(!(cond.assays & cond.se)){fnexclude <- c(fnexclude, f)}
}
}
dm[grepl("h5se", dm[,1]), 4] <- sv
dm <- dm[!dm[,1] %in% fnexclude,] # filter incomplete h5se files
return(dm)
}
get_rmdl <- function(fn = NULL, show.files = FALSE,
which.class = c("rg", "gm", "gr", "test"),
which.type = c("h5se", "h5"),
url = "https://recount.bio/data/",
dfp = "downloads", download = TRUE,
verbose = TRUE, sslver = FALSE){
if(verbose){message("Retrieving data dirnames from server...")}
# set up rcurl call
ftpuseopt <- ifelse(show.files, FALSE, TRUE)
dirlistopt <- ifelse(show.files, FALSE, TRUE)
dn <- RCurl::getURL(url, ftp.use.epsv = ftpuseopt, dirlistonly = dirlistopt,
.opts = list(ssl.verifypeer = sslver))
if(verbose){message("Getting file data from server.")}
sm <- servermatrix(dn)
if(show.files & !download){
if(verbose){message("Showing server file data")}
prmatrix(sm)
}
if(is.null(fn)){
# clean query results
str1 <- ifelse(which.type == "h5", "\\.", ".*")
str2 <- ifelse(which.type == "h5", "$", ".*")
typestr <- paste0(str1, which.type, str2)
filt.type <- grepl(paste0(".*", which.type,".*"), sm[,1])
filt.all <- filt.type & grepl(paste0(".*", which.class,".*"), sm[,1])
dnc <- sm[filt.all, 1]
if(length(dnc) == 0){
stop("No files of class and type found.")
} else if(length(dnc) > 1){
tsv <- as.numeric(gsub(".*_", "", dnc)) # timestamps
tsf <- which(tsv == max(tsv))[1] # first instance
dnc <- dnc[tsf]
}
} else{
dnc <- fn
check.cond1 <- grepl("(\\.h5$|.*h5se.*)", dnc)
check.cond2 <- dnc %in% sm[,1]
condpass <- check.cond1 & check.cond2
if(!condpass){stop("Provided fn not found on server.")}
}
if(!download){
message("File confirmed on server. Returning.")
return(dnc)
}
# manage download loc
dct1 <- ifelse(!dir.exists(dfp) & !dfp == "", try(dir.create(dfp)), TRUE)
dfp.dn <- paste(c(dfp, dnc), collapse = "/")
if(which.type == "h5"){
dct2 <- try(file.create(dfp.dn))
} else{dct2 <- try(dir.create(dfp.dn))}
if(!(dct1 & dct2)){
stop("There was a problem with the download dest. Do you have write access?")
}
dn.url <- paste0(url, dnc)
if(which.type == "h5"){fl.clean <- ""} else{
fnv <- unlist(strsplit(as.character(sm[2,4]), ";"))
fl.clean <- gsub("( .*|`)", "", fnv)
}
if(verbose){message("Downloading file(s)...")}
dll <- list()
for(i in 1:length(fl.clean)){
fpath <- paste0(c(dn.url, fl.clean[i]), collapse = "")
cf = RCurl::CFILE(paste0(dfp.dn, fl.clean[i]), mode="wb")
dll[[i]] <- try(RCurl::curlPerform(url = fpath, writedata = cf@ref,
.opts = list(ssl.verifypeer = sslver)))
}
if(length(dll[dll==0]) == length(dll)){
if(verbose){message("Finished download, returning file path.")}
return(dfp.dn)
} else{
if(verbose){message("Download incomplete for file ", fl.clean[which(dll!=0)])}
return(NULL)
}
return(NULL)
}
get_rmdl(show.files = TRUE, download = FALSE)
servermatrix <- function(dn, url = "https://recount.bio/data/",
printmatrix = TRUE, verbose = FALSE, recursive = TRUE){
dt <- unlist(strsplit(dn, "\r\n"))
dt <- gsub('(.*\">|/</a>|</a>)', "", dt)
dt <- dt[grepl("remethdb", dt)]
drows <- lapply(as.list(dt), function(x){
return(unlist(strsplit(gsub("[ ]+", ";", x), ";")))
})
dm <- do.call(rbind, drows)
colnames(dm) <- c("filename", "date", "time", "size (bytes)")
if(recursive){
sv <- c() # file sizes vector
fnv <- dm[grepl("h5se", dm[,1]), 1]
fnexclude <- c()
for(f in fnv){
fv <- RCurl::getURL(paste0(url, f, "/"), dirlistonly = TRUE,
.opts = list(ssl.verifypeer = sslver))
fvv <- unlist(strsplit(fv, "\r\n"))
which.start <- which(grepl("Index", fvv))[2] + 1
which.end <- which(grepl("/pre", fvv)) - 1
fvf <- fvv[which.start:which.end]
fniv <- c()
for(fni in fvf){
name <- gsub('.*\">', '', gsub("</a>.*", "", fni))
size <- gsub(".* ", "", fni)
fniv <- c(fniv, paste0("`", name, "`", " = ", size))
}
# check for h5se completeness
cond.assays <- length(fniv[grepl("assays", fniv)]) = 1
cond.se <- length(fniv[grepl("se", fniv)]) = 1
sv <- c(sv, paste(fniv, collapse = ";"))
if(!(cond.assays & cond.se)){fnexclude <- c(fnexclude, f)}
}
}
dm[grepl("h5se", dm[,1]), 4] <- sv
dm <- dm[!dm[,1] %in% fnexclude,] # filter incomplete h5se files
return(dm)
}
get_rmdl <- function(fn = NULL, show.files = FALSE,
which.class = c("rg", "gm", "gr", "test"),
which.type = c("h5se", "h5"),
url = "https://recount.bio/data/",
dfp = "downloads", download = TRUE,
verbose = TRUE, sslver = FALSE){
if(verbose){message("Retrieving data dirnames from server...")}
# set up rcurl call
ftpuseopt <- ifelse(show.files, FALSE, TRUE)
dirlistopt <- ifelse(show.files, FALSE, TRUE)
dn <- RCurl::getURL(url, ftp.use.epsv = ftpuseopt, dirlistonly = dirlistopt,
.opts = list(ssl.verifypeer = sslver))
if(verbose){message("Getting file data from server.")}
sm <- servermatrix(dn)
if(show.files & !download){
if(verbose){message("Showing server file data")}
prmatrix(sm)
}
if(is.null(fn)){
# clean query results
str1 <- ifelse(which.type == "h5", "\\.", ".*")
str2 <- ifelse(which.type == "h5", "$", ".*")
typestr <- paste0(str1, which.type, str2)
filt.type <- grepl(paste0(".*", which.type,".*"), sm[,1])
filt.all <- filt.type & grepl(paste0(".*", which.class,".*"), sm[,1])
dnc <- sm[filt.all, 1]
if(length(dnc) == 0){
stop("No files of class and type found.")
} else if(length(dnc) > 1){
tsv <- as.numeric(gsub(".*_", "", dnc)) # timestamps
tsf <- which(tsv == max(tsv))[1] # first instance
dnc <- dnc[tsf]
}
} else{
dnc <- fn
check.cond1 <- grepl("(\\.h5$|.*h5se.*)", dnc)
check.cond2 <- dnc %in% sm[,1]
condpass <- check.cond1 & check.cond2
if(!condpass){stop("Provided fn not found on server.")}
}
if(!download){
message("File confirmed on server. Returning.")
return(dnc)
}
# manage download loc
dct1 <- ifelse(!dir.exists(dfp) & !dfp == "", try(dir.create(dfp)), TRUE)
dfp.dn <- paste(c(dfp, dnc), collapse = "/")
if(which.type == "h5"){
dct2 <- try(file.create(dfp.dn))
} else{dct2 <- try(dir.create(dfp.dn))}
if(!(dct1 & dct2)){
stop("There was a problem with the download dest. Do you have write access?")
}
dn.url <- paste0(url, dnc)
if(which.type == "h5"){fl.clean <- ""} else{
fnv <- unlist(strsplit(as.character(sm[2,4]), ";"))
fl.clean <- gsub("( .*|`)", "", fnv)
}
if(verbose){message("Downloading file(s)...")}
dll <- list()
for(i in 1:length(fl.clean)){
fpath <- paste0(c(dn.url, fl.clean[i]), collapse = "")
cf = RCurl::CFILE(paste0(dfp.dn, fl.clean[i]), mode="wb")
dll[[i]] <- try(RCurl::curlPerform(url = fpath, writedata = cf@ref,
.opts = list(ssl.verifypeer = sslver)))
}
if(length(dll[dll==0]) == length(dll)){
if(verbose){message("Finished download, returning file path.")}
return(dfp.dn)
} else{
if(verbose){message("Download incomplete for file ", fl.clean[which(dll!=0)])}
return(NULL)
}
return(NULL)
}
get_rmdl(show.files = TRUE, download = FALSE)
servermatrix
url = "https://recount.bio/data/"
show.files = TRUE
ftpuseopt <- ifelse(show.files, FALSE, TRUE)
dirlistopt <- ifelse(show.files, FALSE, TRUE)
dn <- RCurl::getURL(url, ftp.use.epsv = ftpuseopt, dirlistonly = dirlistopt,
.opts = list(ssl.verifypeer = sslver))
sslver = FALSE
dn <- RCurl::getURL(url, ftp.use.epsv = ftpuseopt, dirlistonly = dirlistopt,
.opts = list(ssl.verifypeer = sslver))
sm <- servermatrix(dn)
servermatrix <- function(dn, url = "https://recount.bio/data/",
printmatrix = TRUE, verbose = FALSE, recursive = TRUE){
dt <- unlist(strsplit(dn, "\r\n"))
dt <- gsub('(.*\">|/</a>|</a>)', "", dt)
dt <- dt[grepl("remethdb", dt)]
drows <- lapply(as.list(dt), function(x){
return(unlist(strsplit(gsub("[ ]+", ";", x), ";")))
})
dm <- do.call(rbind, drows)
colnames(dm) <- c("filename", "date", "time", "size (bytes)")
if(recursive){
sv <- c() # file sizes vector
fnv <- dm[grepl("h5se", dm[,1]), 1]
fnexclude <- c()
for(f in fnv){
fv <- RCurl::getURL(paste0(url, f, "/"), dirlistonly = TRUE,
.opts = list(ssl.verifypeer = sslver))
fvv <- unlist(strsplit(fv, "\r\n"))
which.start <- which(grepl("Index", fvv))[2] + 1
which.end <- which(grepl("/pre", fvv)) - 1
fvf <- fvv[which.start:which.end]
fniv <- c()
for(fni in fvf){
name <- gsub('.*\">', '', gsub("</a>.*", "", fni))
size <- gsub(".* ", "", fni)
fniv <- c(fniv, paste0("`", name, "`", " = ", size))
}
# check for h5se completeness
cond.assays <- length(fniv[grepl("assays", fniv)]) == 1
cond.se <- length(fniv[grepl("se", fniv)]) == 1
sv <- c(sv, paste(fniv, collapse = ";"))
if(!(cond.assays & cond.se)){fnexclude <- c(fnexclude, f)}
}
}
dm[grepl("h5se", dm[,1]), 4] <- sv
dm <- dm[!dm[,1] %in% fnexclude,] # filter incomplete h5se files
return(dm)
}
sm <- servermatrix(dn)
sm
library(recountmethylation)
?download_h5se_gm
?getrg
?data_mdpost
setwd("~/Documents/GitHub/recount-methylation-analysis/files/data")
library(recountmethylation)
load("~/Documents/GitHub/recount-methylation-analysis/files/data/nct_7tissues_gsm7k.rda")
setwd("~/Desktop/rmlib_todo/recount_methylation/recountmethylation_manuscript1/nctissue_bcdat_new/nctqcid_new")
library(data.table)
adipose <- fread("adipose.gsmid", sep = " ")
adipose
adipose <- fread("adipose.gsmid", sep = " ", header = TRUE)
adipose[1]
adipose <- read("adipose.gsmid", sep = " ")
liver <- read("liver.gsmid", sep = " ")
adipose <- read.table("adipose.gsmid", sep = " ")
liver <- read.table("liver.gsmid", sep = " ")
adipose
adipose <- read.table("adipose.gsmid", sep = " ")[1,]
liver <- read.table("liver.gsmid", sep = " ")[1,]
adipose
adipose <- as.character(read.table("adipose.gsmid", sep = " ")[1,])
liver <- as.character(read.table("liver.gsmid", sep = " ")[1,])
adipose
liver
path <- system.file("extdata", "metadata", package = "recountmethylation")
mdpath <- paste(path, list.files(path)[1], sep = "/")
md <- get(load(mdpath))
mdf <- mdf[mdf$gsm %in% c(adipose, liver),]
path <- system.file("extdata", "metadata", package = "recountmethylation")
mdpath <- paste(path, list.files(path)[1], sep = "/")
md <- get(load(mdpath))
mdf <- md[md$gsm %in% c(adipose, liver),]
dt <- as.data.frame(table(unlist(strsplit(mdf$tissue, ";"))))
dt
mdf2 <- md[grepl("(.*adipose.*|.*liver.*)", md$tissue),]
length(intersect(mdf$gsm, mdf2$gsm)
)
length(intersect(mdf$gsm, mdf2$gsm))
dim(mdf)
load("~/Desktop/rmlib_todo/recount_methylation/recountmethylation_manuscript1/nctissue_bcdat_new/nctqcid_new/nct_7tissues_gsm7k.rda")
length(intersect(gsmv, mdf2$gsm))
length(intersect(gsmv, mdf2$gsm))
length(intersect(gsmv, mdf$gsm))
mdf2 <- md[grepl("(.*adipose.*|.*liver.*)", md$tissue),]
length(intersect(mdf$gsm, mdf2$gsm))
dt2 <- as.data.frame(table(unlist(strsplit(mdf2$tissue, ";"))))
dt2
mdf2 <- md[grepl("(.*adipose.*|.*liver.*)", md$tissue),]
dt2 <- as.data.frame(table(unlist(strsplit(mdf2$tissue, ";"))))
length(intersect(mdf$gsm, mdf2$gsm))
mdf2 <- md[grepl("(.*adipose.*|.*liver.*)", md$tissue),]
mdf2 <- mdf2[!grepl(".*cancer.*", mdf2$disease)]
dt2 <- as.data.frame(table(unlist(strsplit(mdf2$tissue, ";"))))
mdf2 <- md[grepl("(.*adipose.*|.*liver.*)", md$tissue),]
mdf2 <- mdf2[!grepl(".*cancer.*", mdf2$disease),]
dt2 <- as.data.frame(table(unlist(strsplit(mdf2$tissue, ";"))))
dt2
paste('"', adipose,'"', sep = ,)
adipose
v
paste('"', adipose,'"', sep = ",")
paste(paste0('"', adipose,'"'), sep = ",")
paste(paste0('"', adipose,'"'), collapse = ",")
paste(paste0("'", adipose,"'"), collapse = ",")
paste(paste0("'", liver,"'"), collapse = ",")
