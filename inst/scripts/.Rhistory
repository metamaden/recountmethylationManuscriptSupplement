condpass <- check.cond1 & check.cond2
if(!condpass){stop("Provided fn not found on server.")}
}
if(!download){
message("File confirmed on server. Returning.")
return(dnc)
}
# manage download loc
dct1 <- ifelse(!dir.exists(dfp) & !dfp == "", try(dir.create(dfp)), TRUE)
dfp.dn <- paste(c(dfp, dnc), collapse = "/")
if(which.type == "h5"){
dct2 <- try(file.create(dfp.dn))
} else{dct2 <- try(dir.create(dfp.dn))}
if(!(dct1 & dct2)){
stop("There was a problem with the download dest. Do you have write access?")
}
dn.url <- paste0(url, dnc)
if(which.type == "h5"){fl.clean <- ""} else{
fnv <- unlist(strsplit(as.character(sm[2,4]), ";"))
fl.clean <- gsub("( .*|`)", "", fnv)
}
if(verbose){message("Downloading file(s)...")}
dll <- list()
for(i in 1:length(fl.clean)){
fpath <- paste0(c(dn.url, fl.clean[i]), collapse = "")
cf = RCurl::CFILE(paste0(dfp.dn, fl.clean[i]), mode="wb")
dll[[i]] <- try(RCurl::curlPerform(url = fpath, writedata = cf@ref,
.opts = list(ssl.verifypeer = sslver)))
}
if(length(dll[dll==0]) == length(dll)){
if(verbose){message("Finished download, returning file path.")}
return(dfp.dn)
} else{
if(verbose){message("Download incomplete for file ", fl.clean[which(dll!=0)])}
return(NULL)
}
return(NULL)
}
get_rmdl(show.files = TRUE, download = FALSE)
servermatrix <- function(dn, url = "https://recount.bio/data/",
printmatrix = TRUE, verbose = FALSE, recursive = TRUE){
dt <- unlist(strsplit(dn, "\r\n"))
dt <- gsub('(.*\">|/</a>|</a>)', "", dt)
dt <- dt[grepl("remethdb", dt)]
drows <- lapply(as.list(dt), function(x){
return(unlist(strsplit(gsub("[ ]+", ";", x), ";")))
})
dm <- do.call(rbind, drows)
colnames(dm) <- c("filename", "date", "time", "size (bytes)")
if(recursive){
sv <- c() # file sizes vector
fnv <- dm[grepl("h5se", dm[,1]), 1]
fnexclude <- c()
for(f in fnv){
fv <- RCurl::getURL(paste0(url, f, "/"), dirlistonly = TRUE,
.opts = list(ssl.verifypeer = sslver))
fvv <- unlist(strsplit(fv, "\r\n"))
which.start <- which(grepl("Index", fvv))[2] + 1
which.end <- which(grepl("/pre", fvv)) - 1
fvf <- fvv[which.start:which.end]
fniv <- c()
for(fni in fvf){
name <- gsub('.*\">', '', gsub("</a>.*", "", fni))
size <- gsub(".* ", "", fni)
fniv <- c(fniv, paste0("`", name, "`", " = ", size))
}
# check for h5se completeness
cond.assays <- length(fniv[grepl("assays", fniv)]) = 1
cond.se <- length(fniv[grepl("se", fniv)]) = 1
sv <- c(sv, paste(fniv, collapse = ";"))
if(!(cond.assays & cond.se)){fnexclude <- c(fnexclude, f)}
}
}
dm[grepl("h5se", dm[,1]), 4] <- sv
dm <- dm[!dm[,1] %in% fnexclude,] # filter incomplete h5se files
return(dm)
}
get_rmdl <- function(fn = NULL, show.files = FALSE,
which.class = c("rg", "gm", "gr", "test"),
which.type = c("h5se", "h5"),
url = "https://recount.bio/data/",
dfp = "downloads", download = TRUE,
verbose = TRUE, sslver = FALSE){
if(verbose){message("Retrieving data dirnames from server...")}
# set up rcurl call
ftpuseopt <- ifelse(show.files, FALSE, TRUE)
dirlistopt <- ifelse(show.files, FALSE, TRUE)
dn <- RCurl::getURL(url, ftp.use.epsv = ftpuseopt, dirlistonly = dirlistopt,
.opts = list(ssl.verifypeer = sslver))
if(verbose){message("Getting file data from server.")}
sm <- servermatrix(dn)
if(show.files & !download){
if(verbose){message("Showing server file data")}
prmatrix(sm)
}
if(is.null(fn)){
# clean query results
str1 <- ifelse(which.type == "h5", "\\.", ".*")
str2 <- ifelse(which.type == "h5", "$", ".*")
typestr <- paste0(str1, which.type, str2)
filt.type <- grepl(paste0(".*", which.type,".*"), sm[,1])
filt.all <- filt.type & grepl(paste0(".*", which.class,".*"), sm[,1])
dnc <- sm[filt.all, 1]
if(length(dnc) == 0){
stop("No files of class and type found.")
} else if(length(dnc) > 1){
tsv <- as.numeric(gsub(".*_", "", dnc)) # timestamps
tsf <- which(tsv == max(tsv))[1] # first instance
dnc <- dnc[tsf]
}
} else{
dnc <- fn
check.cond1 <- grepl("(\\.h5$|.*h5se.*)", dnc)
check.cond2 <- dnc %in% sm[,1]
condpass <- check.cond1 & check.cond2
if(!condpass){stop("Provided fn not found on server.")}
}
if(!download){
message("File confirmed on server. Returning.")
return(dnc)
}
# manage download loc
dct1 <- ifelse(!dir.exists(dfp) & !dfp == "", try(dir.create(dfp)), TRUE)
dfp.dn <- paste(c(dfp, dnc), collapse = "/")
if(which.type == "h5"){
dct2 <- try(file.create(dfp.dn))
} else{dct2 <- try(dir.create(dfp.dn))}
if(!(dct1 & dct2)){
stop("There was a problem with the download dest. Do you have write access?")
}
dn.url <- paste0(url, dnc)
if(which.type == "h5"){fl.clean <- ""} else{
fnv <- unlist(strsplit(as.character(sm[2,4]), ";"))
fl.clean <- gsub("( .*|`)", "", fnv)
}
if(verbose){message("Downloading file(s)...")}
dll <- list()
for(i in 1:length(fl.clean)){
fpath <- paste0(c(dn.url, fl.clean[i]), collapse = "")
cf = RCurl::CFILE(paste0(dfp.dn, fl.clean[i]), mode="wb")
dll[[i]] <- try(RCurl::curlPerform(url = fpath, writedata = cf@ref,
.opts = list(ssl.verifypeer = sslver)))
}
if(length(dll[dll==0]) == length(dll)){
if(verbose){message("Finished download, returning file path.")}
return(dfp.dn)
} else{
if(verbose){message("Download incomplete for file ", fl.clean[which(dll!=0)])}
return(NULL)
}
return(NULL)
}
get_rmdl(show.files = TRUE, download = FALSE)
servermatrix
url = "https://recount.bio/data/"
show.files = TRUE
ftpuseopt <- ifelse(show.files, FALSE, TRUE)
dirlistopt <- ifelse(show.files, FALSE, TRUE)
dn <- RCurl::getURL(url, ftp.use.epsv = ftpuseopt, dirlistonly = dirlistopt,
.opts = list(ssl.verifypeer = sslver))
sslver = FALSE
dn <- RCurl::getURL(url, ftp.use.epsv = ftpuseopt, dirlistonly = dirlistopt,
.opts = list(ssl.verifypeer = sslver))
sm <- servermatrix(dn)
servermatrix <- function(dn, url = "https://recount.bio/data/",
printmatrix = TRUE, verbose = FALSE, recursive = TRUE){
dt <- unlist(strsplit(dn, "\r\n"))
dt <- gsub('(.*\">|/</a>|</a>)', "", dt)
dt <- dt[grepl("remethdb", dt)]
drows <- lapply(as.list(dt), function(x){
return(unlist(strsplit(gsub("[ ]+", ";", x), ";")))
})
dm <- do.call(rbind, drows)
colnames(dm) <- c("filename", "date", "time", "size (bytes)")
if(recursive){
sv <- c() # file sizes vector
fnv <- dm[grepl("h5se", dm[,1]), 1]
fnexclude <- c()
for(f in fnv){
fv <- RCurl::getURL(paste0(url, f, "/"), dirlistonly = TRUE,
.opts = list(ssl.verifypeer = sslver))
fvv <- unlist(strsplit(fv, "\r\n"))
which.start <- which(grepl("Index", fvv))[2] + 1
which.end <- which(grepl("/pre", fvv)) - 1
fvf <- fvv[which.start:which.end]
fniv <- c()
for(fni in fvf){
name <- gsub('.*\">', '', gsub("</a>.*", "", fni))
size <- gsub(".* ", "", fni)
fniv <- c(fniv, paste0("`", name, "`", " = ", size))
}
# check for h5se completeness
cond.assays <- length(fniv[grepl("assays", fniv)]) == 1
cond.se <- length(fniv[grepl("se", fniv)]) == 1
sv <- c(sv, paste(fniv, collapse = ";"))
if(!(cond.assays & cond.se)){fnexclude <- c(fnexclude, f)}
}
}
dm[grepl("h5se", dm[,1]), 4] <- sv
dm <- dm[!dm[,1] %in% fnexclude,] # filter incomplete h5se files
return(dm)
}
sm <- servermatrix(dn)
sm
library(recountmethylation)
?download_h5se_gm
?getrg
?data_mdpost
utils::news(package="recountmethylation")
library(recountmethylation)
utils::news(package="recountmethylation")
?news
news(package = "utils")
library(minfi)
news(package = "minfi")
utils::news(package = "minfi")
suppressMessages(library(rhdf5))
suppressMessages(library(minfi))
suppressMessages(library(recountmethylation))
suppressMessages(library(knitr))
suppressMessages(library(ggplot2))
suppressMessages(library(gridExtra))
opts_chunk$set(eval = FALSE, echo = TRUE,
warning = FALSE, message = FALSE)
# load rdata
sf <- system.file(file.path("extdata", "data_analyses"),
package = "recountmethylation")
load(file.path(sf, "data_analyses.RData"))
load("~/Desktop/recount-rep/get_studies/SRP012682_gtexsubset/rse_gene.Rdata")
dim(rse_gene)
library(recountmethylation)
library(recountmethylation)
cite(recountmethylation)
cite("recountmethylation")
library(minfi)
cite(minfi)
cite("minfi")
citation(recountmethylation)
citation("recountmethylation")
citation("minfi")
library(recountmethylation)
sm <- get_rmdl(download = FALSE)
sm
class(sm)
sm <- get_rmdl(show.files = TRUE, download = FALSE)
sm
url = "https://recount.bio/data/"
show.files = FALSE
sslver = FALSE
ftpuseopt <- dirlistopt <- ifelse(show.files, FALSE, TRUE) # rcurl setup
dn <- RCurl::getURL(url, ftp.use.epsv = ftpuseopt, dirlistonly = dirlistopt,
.opts = list(ssl.verifypeer = sslver))
sm <- servermatrix(dn = dn, sslver = sslver)
dim(sm)
ncol(sm)
colnames(sm)
sm
class(sm)
is.matrix(sm)
class(sm[,1])
gds_idat2rg(c("GSM2465267", "GSM2814572"))
?gds_idat2rg
?gds_idatquery
devtools::test("recountmethylation")
install.packages("R.utils")
if (!requireNamespace("BiocManager", quietly = TRUE))
install.packages("BiocManager")
BiocManager::install("BiocFileCache")
library(recountmethylation)
getdb_h5_test()
getdb_h5_test()
?readline
readline("aaaaa\naaaaaaa")
readlines("aaaaaa\naaaaaa")
readLines("aaaaaa\naaaaaa")
library(recountmethylation)
getdb_h5_test()
getdb_h5_test()
library(recountmethylation)
getdb_h5_test()
getdb_h5se_test()
getdb_h5se_test()
getdb_h5se_test()
dat <- getdb_h5se_test()
ls()
c <- 1
ls()
library(recountmethylation)
library(ExperimentHub)
BiocManager::install("ExperimentHub")
library(ExperimentHub)
hub = ExperimentHub()
file = hub[["EH3773"]]
file
hub
file
hub[["EH3773"]]
browseVignettes("recountmethylation")
query(hub, "recountmethylation")
eid <- "EH3776"
apData[[eid]]
rmdat <- query(hub, "recountmethylation")
rmdat
eid <- "EH3776"
rmdat[[eid]]
hub[["EH3773"]]
rmdat
eid <- "EH3778"
rmdat[[eid]]
dim(rmdat)
rmdat[[eid]]
list.files(/Users/maden/Library/Caches/ExperimentHub/59b359558941_3814)
list.files("/Users/maden/Library/Caches/ExperimentHub/59b359558941_3814")
list.files("Users/maden/Library/Caches/ExperimentHub/")
list.files("Users/maden/Library/Caches/ExperimentHub")
eid <- "EH3778"
dat <- rmdat[[eid]]
dim(dat)
class(dat)
dat
colnames(dat)
rmdat
eid <- "EH3776"
rmdat[[eid]]
bfcadd()
object[["EH3773"]]
rmdat[["EH3773"]]
rmdat[["EH3778"]]
rmdat
possibleDates(rmdat)
snapshotDate(rmdat)
library(GenomicRanges)
?subsetByOverlaps
?mclapply
jvect <- c(1,2,3)
jvect ^ 2
jvect^2
sum(0)
0/sum(0)
load("/Users/maden/Desktop/recount-rep/spliceclock_project/gtexv2/jxcounts_sampfilt15000/jxtotcount_minsampfilt15000.rda")
colnames(samp)
summary(samp$jx.count.minsamp15000)
summary(samp$jx.reads.minsamp15000)
devtools::install_github("hhhh5/ewastools")
library(ewastools)
load("~/Documents/GitHub/recountmethylation/inst/extdata/metadata/md_00-00-01_1583780004.rda")
head(md$gsm)
head(md$gseid)
?prcomp
setwd("~/Documents/GitHub/recountmethylationManuscriptSupplement/vignettes")
pkgname <- "recountmethylationManuscriptSupplement"
path <- system.file("scripts", package = pkgname)
path
sp <- file.path(path, "fig1a.R")
sp
pkgname <- "recountmethylationManuscriptSupplement"
scripts.dir <- system.file("scripts", package = pkgname)
library(recountmethylationManuscriptSupplement)
pkgname <- "recountmethylationManuscriptSupplement"
scripts.dir <- system.file("scripts", package = pkgname)
library(ggplot2)
library(gridExtra)
library(data.table)
knitr::opts_chunk$set(echo = TRUE, eval = FALSE)
script.name <- "figS1.R"
source(file.path(scripts.dir, script.name))
figS1
script.name <- "figS1.R"
source(file.path(scripts.dir, script.name))
figS1
script.name <- "figS1.R"
source(file.path(scripts.dir, script.name))
figS1
script.name <- "figS1.R"
source(file.path(scripts.dir, script.name))
figS1
library(ggplot2)
#!/usr/bin/env R
# Make Figure 1A panel plot of cumulative GEO samples (GSMs)
# by year and available sample type.
library(ggplot2)
library(data.table)
pkgname <- "recountmethylationManuscriptSupplement"
tables.dir <- system.file("extdata", "geodata", package = pkgname)
#--------------
# platform info
#--------------
lid <- list(c('GPL13534','HM450K','2011','May 2011'),
c('GPL21145', 'EPIC','2015','Nov. 2015'),
c('GPL8490', 'HM27K','2009','Apr. 2009')
)
keydf <- as.data.frame(do.call(rbind, lid))
colnames(keydf) <- c("platform_id", "platform_name",
"release_year", "release_month")
#----------------------------
# load and format data tables
#----------------------------
# specify tables
fnv <- c("gseyeardata", "gseidatyrdat")
# load sample data
dm <- do.call(rbind, lapply(fnv, function(x){
return(fread(file.path(tables.dir, x), sep = " ", data.table = FALSE))
}))
df <- as.data.frame(dm, stringsAsFactors = FALSE)
colnames(df) <- c("platformid","year","samples")
# filter platforms of interest
which.platforms <- c("GPL8490", "GPL13534", "GPL21145")
df <- df[df$platformid %in% which.platforms,]
# append sample types
stype <- c(rep(" (all)", 60), rep(" (idat)", 60))
df$plab <- paste0(df$platformid, stype)
# get formatted columns/labels
df$year <- as.numeric(df$year); df$pname <- "NA"
dff <- matrix(nrow = 0, ncol = 5)
for(pid in keydf[,1]){
ki <- keydf[keydf[,1] == pid,]
release.yr <- as.numeric(ki[3])
dpid <- df[df$platformid == pid,]
dpid <- dpid[dpid$year >= release.yr,]
dpid$pname <- paste0(gsub(" .*", "", ki[2]),
" ", gsub(".* ", "", dpid$plab))
dpid <- dpid[order(dpid$year),]
for(u in unique(dpid$plab)){
dpp <- dpid[dpid$plab == u,]
for(r in seq(nrow(dpp))){
dfi <- dpp[r,]
dfi[3] <- sum(dpp[seq(r),3])
dff <- rbind(dff, dfi)
}
}
}
dff <- as.data.frame(dff, stringsAsFactors = FALSE)
dff$platform <- gsub(" .*", "", dff$pname)
#------------
# make ggplot
#------------
# make plot
dff$`Platform (Type)` <- dff$plab
lv <- c("HM450K (all)", "HM450K (idat)", "EPIC (all)", "EPIC (idat)", "HM27K (all)", "HM27K (idat)")
vv <- c("green", "forestgreen", "blue", "cyan", "gold", "brown")
sv <- c(17, 17, 16, 16, 18, 18)
lname <- "Platform (Type)"
figS1 <- ggplot(dff, aes(year, samples)) + theme_bw() +
xlab("Year") + ylab("Cumulative Samples") +
geom_point(aes(colour = `Platform (Type)`, shape = platform)) +
guides(shape = FALSE) +
scale_shape_manual(values = sv) +
scale_colour_manual(values = vv) +
guides(colour = guide_legend(override.aes = list(shape = sv, colour = vv))) +
geom_line(data = dff[dff$pname == "HM27K (idat)",],
aes(year, samples), color = "brown") +
geom_line(data = dff[dff$pname == "HM27K (all)",],
aes(year, samples), color = "gold") +
geom_line(data = dff[dff$pname == "HM450K (all)",],
aes(year, samples), color = "green") +
geom_line(data = dff[dff$pname == "HM450K (idat)",],
aes(year, samples), color = "forestgreen") +
geom_line(data = dff[dff$pname == "EPIC (all)",],
aes(year, samples), color = "blue") +
geom_line(data = dff[dff$pname == "EPIC (idat)",],
aes(year, samples), color = "cyan") +
theme(legend.position = c(0.2, 0.6))
figS1
script.name <- "figS1.R"
source(file.path(scripts.dir, script.name))
figS1
file.path(scripts.dir, script.name)
setwd("~/Documents/GitHub/recountmethylationManuscriptSupplement/inst/extdata/tables")
load("~/Documents/GitHub/recount-methylation-analysis/files/data/qcmd_allmetrics_allgsm.rda")
colnames(qcmd)
old <- read.csv("table-s2_qcmd_allgsm.csv")
old <- read.csv("table-s2_qcmd-allgsm.csv")
colnames(old)
identical(old$gsm, qcmd$gsm)
identical(old$ba.restoration.grn, qcmd$ba.restoration.grn)
class(old$ba.restoration.grn)
class(qcmd$ba.restoration.grn)
head(old$ba.restoration.grn)
head(qcmd$ba.restoration.grn)
identical(old$ba.restoration.grn, round(qcmd$ba.restoration.grn,2))
new <- qcmd[,intersect(colnames(old), colnames(qcmd))]
colnames(new)
setwd("~/Documents/GitHub/recountmethylationManuscriptSupplement/inst/scripts")
pkgname <- "recountmethylationManuscriptSupplement"
tables.dir <- system.file("extdata", "tables", package = pkgname)
fn <- "table-s2_qcmd-allgsm.csv"
qcmd <- read.csv(file.path(tables.dir, fn))
gsev = unique(qcmd$gseid)
gsesize = c()
for(g in gsev){gsesize = c(gsesize, length(which(qcmd$gseid==g)))}
st.agg = data.frame(ngsm = gsesize) # agg for supp table
gm = matrix(nrow = 0, ncol = 17)
bat = bathresh(bam)
bat = bat[,c(2:ncol(bat))]
for(g in gsev){
ngsm = nrow(qcmd[qcmd$gseid==g,])
if(ngsm > 4){
bag = apply(bat[rownames(bat) %in% qcmd[qcmd$gseid==g,]$gsm,],
2,
function(x){length(x[x=="FAIL"])/ngsm})
gm = rbind(gm, matrix(c(bag), nrow = 1))
}
message(g)
}
colnames(gm) = colnames(bat)
rownames(gm) = gsev
class(gm) = "numeric"
hm.baf = gm
library(recountmethylationManuscriptSupplement)
gm = matrix(nrow = 0, ncol = 17)
bat = bathresh(bam)
bat = bat[,c(2:ncol(bat))]
